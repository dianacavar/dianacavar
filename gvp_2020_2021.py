# -*- coding: utf-8 -*-
"""GVP 2020_2021

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J4iV0dbjAzze4PmIpATT5pYC1yULJN5N

#*Ponderación del riesgo con delegados del Gobierno Nacional en la UNP 2020 Y 2021*

# Librerias
"""

!pip install sodapy

import pandas as pd
from sodapy import Socrata
import numpy as np
import seaborn as sns

#LIBRERIAS DE VISUALIZACIÓN
import matplotlib.pylab as plt # Herramienta principal de visualización https://matplotlib.org/stable/contents.html
import matplotlib.dates as mdates # Dentro de matplotlib, tenemos una herramienta para manejo de fechas

"""BASE DE DATOS"""

client = Socrata("www.datos.gov.co", None)
results = client.get("gafa-aef3", limit=35000) # Con limite de 1.000 filas (Filas 3,98M)

df = pd.DataFrame.from_records(results)


client = Socrata("www.datos.gov.co", None)
results = client.get("czs7-pwfx", limit=35000) # Con limite de 1.000 filas (Filas 3,98M)
results2 = client.get("xr34-dvva", limit=35000) # Con limite de 1.000 filas (Filas 3,98M)

UNP_2020 = pd.DataFrame.from_records(results)
UNP_2021 = pd.DataFrame.from_records(results2)

from google.colab import drive

drive.mount('/content/drive')

filename = '/content/drive/My Drive/cod_dane1.xlsx' 

dane = pd.read_excel(filename)

# Ver las primeras filas del DataFrame
print(dane.head())
#dane["COD_DANE"] = dane["COD_DANE"].apply(str)

dane.info()

"""#Eliminar comillas de las variables longitud y latitud
dane["LATITUD"] = dane["LATITUD"].str.replace(",", ".")
dane["LONGITUD"] = dane["LONGITUD"].str.replace(",", ".")

#Convertir las variables longitud y latitud de string(objeto) a float
dane["LATITUD"] = dane["LATITUD"].apply(float)
dane["LONGITUD"] = dane["LONGITUD"].apply(float)

UNION BASES 2020 y 2021 DE LA UNP
"""

#unir bases, tambien puedo usar pd.concat
df=pd.merge(UNP_2020, UNP_2021, how="outer")
df.head(2)

# Unificar Departamentos Reemplaza numero
df['departamento'] = df['departamento'].replace('ATLÁNTICO','ATLANTICO')
df['departamento'] = df['departamento'].replace('BOLÍVAR','BOLIVAR')
df['departamento'] = df['departamento'].replace('CAQUETÁ','CAQUETA')
df['departamento'] = df['departamento'].replace('CHOCÓ','CHOCO')
df['departamento'] = df['departamento'].replace('CÓRDOBA','CORDOBA')
df['departamento'] = df['departamento'].replace('GUAJIRA','LA GUAJIRA')
df['departamento'] = df['departamento'].replace('NORTE SANTANDER','NORTE DE SANTANDER')
df['departamento'] = df['departamento'].replace('QUINDÍO','QUINDIO')
df['departamento'] = df['departamento'].replace('SAN ANDRES','ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA')
df['departamento'] = df['departamento'].replace('VALLE','VALLE DEL CAUCA')
df['departamento'] = df['departamento'].replace('VAUPÉS','VAUPES')

# Unificar Municipios Reemplaza numero
df['municipio'] = df['municipio'].replace('CARMEN DE VIBORAL','EL CARMEN DE VIBORAL')
df['municipio'] = df['municipio'].replace('DON MATIAS','DONMATIAS')
df['municipio'] = df['municipio'].replace('ITAGUI','ITAGÜI')
df['municipio'] = df['municipio'].replace('YONDO (CASABE)','YONDO')
df['municipio'] = df['municipio'].replace('CARTAGENA','CARTAGENA DE INDIAS')
df['municipio'] = df['municipio'].replace('MOMPOS','SANTA CRUZ DE MOMPOX')
df['municipio'] = df['municipio'].replace('TIQUISIO (PUERTO RICO)','TIQUISIO')
df['municipio'] = df['municipio'].replace('TOGUI','TOGÜI')
df['municipio'] = df['municipio'].replace('LOPEZ (MICAY)','LOPEZ DE MICAY')
df['municipio'] = df['municipio'].replace('PAEZ (BELALCAZAR)','PAEZ')
df['municipio'] = df['municipio'].replace('PATIA(EL BORDO)','PATIA')
df['municipio'] = df['municipio'].replace('PIENDAMO','PIENDAMO - TUNIA')
df['municipio'] = df['municipio'].replace('PURACE (COCONUCO)','PURACE')
df['municipio'] = df['municipio'].replace('SOTARA (PAISPAMBA)','SOTARA PAISPAMBA')
df['municipio'] = df['municipio'].replace('LA PAZ (ROBLES)','LA PAZ')
df['municipio'] = df['municipio'].replace('ALTO BAUDO (PIE DE PATO)','ALTO BAUDO')
df['municipio'] = df['municipio'].replace('ATRATO (YUTO)','ATRATO')
df['municipio'] = df['municipio'].replace('BAHIA SOLANO (MUTIS)','BAHIA SOLANO')
df['municipio'] = df['municipio'].replace('BAJO BAUDO (PIZARRO)','BAJO BAUDO')
df['municipio'] = df['municipio'].replace('BOJAYA (BELLAVISTA)','BOJAYA')
df['municipio'] = df['municipio'].replace('CANTON DEL SAN PABLO','EL CANTON DEL SAN PABLO')
df['municipio'] = df['municipio'].replace('LA APARTADA (LA FRONTERA)','LA APARTADA')
df['municipio'] = df['municipio'].replace('SAN ANDRES SOTAVENTO','SAN ANDRES DE SOTAVENTO')
df['municipio'] = df['municipio'].replace('UBATE','VILLA DE SAN DIEGO DE UBATE')
df['municipio'] = df['municipio'].replace('VENECIA (OSPINA PEREZ)','VENECIA')
df['municipio'] = df['municipio'].replace('ARIGUANI (EL DIFICIL)','ARIGUANI')
df['municipio'] = df['municipio'].replace('CERRO SAN ANTONIO','CERRO DE SAN ANTONIO')
df['municipio'] = df['municipio'].replace('CHIBOLO','CHIVOLO')
df['municipio'] = df['municipio'].replace('LA URIBE','URIBE')
df['municipio'] = df['municipio'].replace('VISTA HERMOSA','VISTAHERMOSA')
df['municipio'] = df['municipio'].replace('ALBAN (SAN JOSE)','ALBAN')
df['municipio'] = df['municipio'].replace('ARBOLEDA (BERRUECOS)','ARBOLEDA')
df['municipio'] = df['municipio'].replace('CHACHAGUI','CHACHAGÜI')
df['municipio'] = df['municipio'].replace('COLON (GENOVA)','COLON')
df['municipio'] = df['municipio'].replace('MAGUI (PAYAN)','MAGÜI')
df['municipio'] = df['municipio'].replace('MALLAMA (PIEDRANCHA)','MALLAMA')
df['municipio'] = df['municipio'].replace('ROBERTO PAYAN (SAN JOSE)','ROBERTO PAYAN')
df['municipio'] = df['municipio'].replace('SANTA BARBARA (ISCUANDE)','SANTA BARBARA')
df['municipio'] = df['municipio'].replace('SANTACRUZ (GUACHAVES)','SANTACRUZ')
df['municipio'] = df['municipio'].replace('TUMACO','SAN ANDRES DE TUMACO')
df['municipio'] = df['municipio'].replace('CUCUTA','SAN JOSE DE CUCUTA')
df['municipio'] = df['municipio'].replace('DOS QUEBRADAS','DOSQUEBRADAS')
df['municipio'] = df['municipio'].replace('GUEPSA','GÜEPSA')
df['municipio'] = df['municipio'].replace('GALERAS (NUEVA GRANADA)','GALERAS')
df['municipio'] = df['municipio'].replace('TOLU','SANTIAGO DE TOLU')
df['municipio'] = df['municipio'].replace('TOLUVIEJO','SAN JOSE DE TOLUVIEJO')
df['municipio'] = df['municipio'].replace('ARMERO (GUAYABAL)','ARMERO')
df['municipio'] = df['municipio'].replace('MARIQUITA','SAN SEBASTIAN DE MARIQUITA')
df['municipio'] = df['municipio'].replace('BUGA','GUADALAJARA DE BUGA')
df['municipio'] = df['municipio'].replace('CALIMA (DARIEN)','CALIMA')

#CREAR VARIABLE LUGAR PARA CONCATENAR DEPARTAMENTO Y MUNICIPIO Y ASI PODER TRAER EL CODIGO DANE QUE ES ID POR MUNICIPIO (PERO SE UNE CON DEPARTAMENTO PORQUE ALGUNOS TIENEN MUNICIPIOS CON EL MISMO NOMBRE)
df["LUGAR"] = df["departamento"]+"-" +df["municipio"]
print("frecuencia por lugar",df["LUGAR"].nunique())

df['LUGAR'] = df['LUGAR'].replace('LA GUAJIRA-MANAURE BALCON DEL CESAR', 'LA GUAJIRA-MANAURE')
df['LUGAR'] = df['LUGAR'].replace('CESAR-MANAURE', 'CESAR-MANAURE BALCON DEL CESAR')

"""##Traer Código DANE"""

# Unimos los dataframes por la columna común 'LUGAR'
df_merged = pd.merge(df, dane, on='LUGAR', how='left')
df_merged.head(2)

"""#Eliminar comillas de las variables longitud y latitud
df_merged["LATITUD"] = df_merged["LATITUD"].str.replace(",", ".")
df_merged["LONGITUD"] = df_merged["LONGITUD"].str.replace(",", ".")

#Convertir las variables longitud y latitud de string(objeto) a float
df_merged["LATITUD"] = df_merged["LATITUD"].apply(float)
df_merged["LONGITUD"] = df_merged["LONGITUD"].apply(float)"""

df_merged.info()
# Exportamos el dataframe a un archivo Excel
"""!pip install openpyxl

df_merged.to_csv('df_merged.csv', index=False)"""

#validar los nulos del merge de la base de la unp y dane
# Identificamos los valores nulos de la variable 'COD_DANE'
valores_nulos = df_merged['COD_DANE'].isnull()
print(valores_nulos)

# Seleccionamos los Lugares correspondientes a los valores nulos
Lugares_nulos = df_merged.loc[valores_nulos, 'LUGAR'].unique()
print(Lugares_nulos)

#revision cod dane
print("frecuencia por cod",df_merged["COD_DANE"].nunique())

"""TRAER BASE DE ASESINATOS LIDERES"""

#BASE ASESINATOS
from google.colab import drive
drive.mount('/content/drive')
filename = '/content/drive/My Drive/AsesinatosLideres.csv' 
asesinatos = pd.read_csv(filename,  sep=";")
asesinatos

#MEDIA
asesinatos['TOTAL'].mean()

#MEDIA SIN EL DATO ATIPICO

promedio = asesinatos['TOTAL'][asesinatos['TOTAL'] < asesinatos['TOTAL'].mean() + 2*asesinatos['TOTAL'].std()].mean()
print("Promedio sin valor atípico: ", promedio)

import matplotlib.pyplot as plt
#Gráfico de distribución normal
count, bins, ignored = plt.hist(asesinatos['TOTAL'], 15, density=True) 

# Agregar etiquetas y título al gráfico
plt.xlabel('N° de asesinatos')
plt.ylabel('Frecuencia')
plt.title('Distribución normal')
plt.show()

#Boxplot
import seaborn as sns

# Crear el boxplot utilizando Seaborn
sns.boxplot(x='TOTAL', data=asesinatos)

# Agregar título al gráfico
plt.title('Asesinatos')

# Mostrar el gráfico
plt.show()

"""#UNIR LA BASE DE INDEPAZ CON LA BASE DEL DANE, PERO SOLO TRAER EL CODIGO
indepaz = pd.merge(asesinatos, dane[['LUGAR', 'COD_DANE']], on='LUGAR', how='left')
print(indepaz)

#validar los nulos del merge de la base de asesinatos  y el dane
# Identificamos los valores nulos de la variable 'COD_DANE'
valores_nulos = indepaz['COD_DANE'].isnull()
# Seleccionamos los Lugares correspondientes a los valores nulos
#Lugares_nulos = indepaz.loc[valores_nulos, 'LUGAR'].nunique()
Lugares_nulos = indepaz.loc[valores_nulos, 'LUGAR'].unique()
print(Lugares_nulos)

PROCESAMIENTO CON BASE DF_MERGED
"""

#Creo nueva base con solo las variables a trabajar y ya concatenada el cod_dane
df_riesgo = df_merged.loc[:,['COD_DANE','poblaci_n', 'departamento','municipio', 'nivel_del_riesgo', 'g_nero']]
#hacer que el ID sea el Cod_dane
df_riesgo = df_riesgo.set_index("COD_DANE")
df_riesgo.info()

# Unimos los dataframes de riesgo y asesinatos por la columna común 'COD_DANE'
df_unp = pd.merge(df_riesgo, asesinatos[['COD_DANE', 'TOTAL']], on='COD_DANE', how='left')
df_unp.head(2)

#Revisión general de la concatenacion para evaluar si unio todos los codigos
df_unp.info()

#validar los nulos del merge de la base de riesgo y asesinatos
# Identificamos los valores nulos de la variable 'COD_DANE'
valores_nulos = df_unp['TOTAL'].isnull()

# Seleccionamos los Lugares correspondientes a los valores nulos
Lugares_nulos = df_unp.loc[valores_nulos, 'COD_DANE'].nunique()
print(Lugares_nulos)

df_unp.to_csv('df_unp.csv', index=False)

"""# Limpieza de datos"""

df.head(5)

# Convierte las columnas tipo objeto a fecha
df['a_o'] = pd.to_datetime(df['a_o'])
df.dtypes

# Calcula algunas estadisticas descriptivas/ incluso las categoricas
print(df.describe(include="all"))

# frecuencias por variables de las ENR sustentadas en amenaza
print("Frecuencia por año \n", df["a_o"].value_counts())
print("Frecuencia por mes \n", df["mes"].value_counts())
print("Frecuencia por Nivel de Riesgo \n",df["nivel_del_riesgo"].value_counts())
print("Frecuencia por Grupo poblacional \n",df["poblaci_n"].value_counts())
print("Frecuencia por Categoría \n",df["subpoblaci_n"].value_counts())
print("Frecuencia por Departamento \n",df["departamento"].value_counts())
print("Frecuencia por Municipio \n",df["municipio"].value_counts())
print("Frecuencia por Género \n",df["g_nero"].value_counts())

"""FRECUENCIAS RELATIVAS"""

#Tambien se puede de esta forma sacar la frecuencia relativa
round(df["nivel_del_riesgo"].value_counts(normalize= True, ascending=False),2)

#Tambien se puede de esta forma sacar la frecuencia relativa
round(df["g_nero"].value_counts(normalize= True, ascending=False),2)

"""##VISUALIZACION"""

#Gráfico de torta
plot = df['nivel_del_riesgo'].value_counts().plot(kind='pie', autopct='%.2f', 
                                            figsize=(6, 6),
                                            title='% NR')
"""
#Gráfico de torta por genero
plot = df['g_nero'].value_counts().plot(kind='pie', autopct='%.2f', 
                                            figsize=(6, 6),
                                            title='% NR')"""

#GRAFICO DE POBLACIONES
df['poblaci_n'].value_counts(ascending=True).plot(kind='barh', width=0.8, figsize=(9,4))


"""#GRAFICO FRECUENCIA RELATIVA
freq_rel = df['poblaci_n'].value_counts(normalize=True, ascending=True)
# Gráfico de barras con frecuencias relativas
freq_rel.plot(kind='barh', width=0.8, figsize=(9,4), color= "#FFD700")"""

#GRAFICO DE DEPARTAMENTOS POR PONDERACION 

# Filtrar los registros de la ponderacion 
Extremo = df.loc[df["nivel_del_riesgo"] == "Extremo"]

# Contar los valores de variable2 en los registros filtrados
Total_extremo = Extremo["departamento"].value_counts(ascending=True)

# Crear el gráfico utilizando matplotlib
Total_extremo.plot(kind="barh", color= "#FF0000")

# Agregar etiquetas de eje y título
plt.xlabel("ENR")
plt.ylabel("Departamento")
plt.title("ENR con ponderacion Extremo por departamento")

# Mostrar el gráfico
plt.show()

#GRAFICO DE DEPARTAMENTOS POR PONDERACION 

# Filtrar los registros de la ponderacion 
Extraordinario = df.loc[df["nivel_del_riesgo"] == "Extraordinario"]

# Contar los valores de variable2 en los registros filtrados
Total_Extraordinario = Extraordinario["departamento"].value_counts(ascending=True)

# Crear el gráfico utilizando matplotlib
Total_Extraordinario.plot(kind="barh", color= "#FF8000")

# Agregar etiquetas de eje y título
plt.xlabel("ENR")
plt.ylabel("Departamento")
plt.title("ENR con ponderacion Extraordinario por departamento")

# Mostrar el gráfico
plt.show()

#GRAFICO FRECUENCIA RELATIVA
freq_rel = df['departamento'].value_counts(normalize=True, ascending=True)
# Gráfico de barras con frecuencias relativas
freq_rel.plot(kind='barh' ,figsize=(3,6) )

"""##RELACION DE VARIABLES"""

#TABLA DE CONTINGENCIA ENTRE POBLACION Y PONDERACION, con el margins saco totales y con sort values organizo en orden descendente por el total

pd.crosstab(index=df['poblaci_n'],
            columns=df['nivel_del_riesgo'] , margins=True).sort_values(by="All", ascending=False).head(5)

#TABLA DE CONTINGENCIA ENTRE GENERO Y PONDERACION ...El margins son los totales y el normalize para que salga en %

round(pd.crosstab(index=df['g_nero'],
            columns=df['nivel_del_riesgo'],margins=True, normalize = True),2)

#GRAFICA DE BARRAS ENTRE GENERO Y PONDERACION
plot= pd.crosstab(index=df['nivel_del_riesgo'],
            columns=df['g_nero'], normalize = True).plot(kind='barh')

"""###PRUEBA CHI-CUADRADO"""

#TABLA DE CONTINGENCIA 3 VARIABLES 

# Creamos una tabla de contingencia con las tres variables
tabla_contingencia = pd.crosstab(index=[df['poblaci_n'], df['g_nero']], columns=df['nivel_del_riesgo'], margins=True).head(3)

print(tabla_contingencia)

# Realizamos la prueba de chi-cuadrado
from scipy.stats import chi2_contingency
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)
"print('Frecuencias esperadas: ', expected)"

# Creamos una tabla de contingencia con con 2 variables
tabla_contingencia = pd.crosstab(index=df['nivel_del_riesgo'], columns=df['g_nero'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

# Creamos una tabla de contingencia con con 2 variables
tabla_contingencia = pd.crosstab(index=df['departamento'], columns=df['nivel_del_riesgo'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

# Creamos una tabla de contingencia con con 2 variables
tabla_contingencia = pd.crosstab(index=df['poblaci_n'], columns=df['nivel_del_riesgo'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

# Creamos una tabla de contingencia con 2 variables
tabla_contingencia = pd.crosstab(index=df['departamento'], columns=df['g_nero'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

# Creamos una tabla de contingencia con 2 variables
tabla_contingencia = pd.crosstab(index=df['poblaci_n'], columns=df['g_nero'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

# Creamos una tabla de contingencia con 2 variables
tabla_contingencia = pd.crosstab(index=df['nivel_del_riesgo'], columns=df['municipio'] , margins=True).head(3)
print(tabla_contingencia)
# Realizamos la prueba de chi-cuadrado
chi2, p, dof, expected = chi2_contingency(tabla_contingencia)

# Imprimimos los resultados
print('Estadístico de prueba chi-cuadrado: ', chi2)
print('Valor p: ', p)
print('Grados de libertad: ', dof)

"""##GEOREFERENCIACIÓN"""

!pip install geopandas
import geopandas as gpd

#Grafica dane
dane_geo =  gpd.GeoDataFrame(dane, geometry=gpd.points_from_xy(dane.LONGITUD, dane.LATITUD))
dane_geo.plot()

#Conteo de municipios con ENR por Código DANE
unp_conteo = df_merged.groupby("COD_DANE")["municipio"].agg(['count'])
unp_conteo

#SE CONCATENA LA BASE DEL DANE TOTAL DE LOS 1122 MUNICIPIOS CON LA DE LA UNIDAD CON UN CONTEO DE 709 MUNICIPIOS (El "outer" es para que traiga todo, no solo en comun)
test = dane_geo.merge(unp_conteo, left_on='COD_DANE', right_on='COD_DANE', how="outer").sort_values(by = 'count', ascending = False)
test.head(3)

axis = gdf.plot(figsize = (6, 5))
test.plot(column = "count", ax = axis, legend = True)

"""PROCESAMIENTO BASE DF_UNP QUE INCLUYE LOS ASESINATOS"""

#Cambio nombre de columna
df_unp = df_unp.rename(columns={'TOTAL': 'N_Asesinatos'})
#COD_DANE A STR
df_unp['COD_DANE'] = df_unp['COD_DANE'].astype(str)
df_unp.head()

"""AGRUPAR"""

#Agrupar los municipios por el # de asesinatos reportados por Indepaz/eliminar los nulos
media_riesgo_asesinato = df_unp.dropna().groupby(['nivel_del_riesgo']).mean().sort_values(by='N_Asesinatos', ascending=False)
media_riesgo_asesinato

#Agrupar los municipios por el # de asesinatos reportados por Indepaz/eliminar los nulos
media_riesgo_asesinato = df_unp.dropna().groupby([ 'g_nero']).mean().sort_values(by='N_Asesinatos', ascending=False)
media_riesgo_asesinato

import matplotlib.pyplot as plt
#Gráfico de distribución normal
count, bins, ignored = plt.hist(df_unp['N_Asesinatos'], 15, density=True) 

# Agregar etiquetas y título al gráfico
plt.xlabel('N° de asesinatos')
plt.ylabel('Frecuencia')
plt.title('Distribución normal')
plt.show()

#BOXPLOT POR CATEGORIAS
#grafico_a=sns.boxplot(x='g_nero', y='N_Asesinatos', data=df_unp)
grafico_b=sns.boxplot(x='nivel_del_riesgo', y='N_Asesinatos', data=df_unp)



#APLICO T-STUDENT PARA ANALIZAR LA RELACIÓN ENTRE DOS VARIABLES (CUALITATIVA Y CUANTITATIVA)

from scipy.stats import ttest_ind

# Seleccionar la variable cuantitativa y la variable categórica
variable_cuanti = df_unp['N_Asesinatos']
variable_categ = df_unp['g_nero']

# Aplicar la prueba T de Student
t_stat, p_val = ttest_ind(variable_cuanti[variable_categ == 'categoria_1'],
                          variable_cuanti[variable_categ == 'categoria_2'])

# Imprimir los resultados
print('Estadístico T: ', t_stat)
print('Valor p: ', p_val)

"""RELACION

PRUEBA ESTADISTICA ANOVA 
Para evaluar si hay diferencias significativas entre los grupos definidos por la variable categórica.
"""

